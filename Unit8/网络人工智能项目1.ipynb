{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è¯†åˆ«VPNæµé‡ ğŸ•µï¸â€â™‚ï¸\n",
    "* ä½¿ç”¨ Tensorflow æ­å»ºç¥ç»ç½‘ç»œå®ŒæˆVPNæµé‡çš„è¯†åˆ«\n",
    "* FIAT: å‘å‰å‘é€ä¸¤ä¸ªæ•°æ®åŒ…ä¹‹é—´çš„æ—¶é—´ï¼ˆå¹³å‡å€¼ï¼Œæœ€å¤§å€¼ï¼Œæœ€å°å€¼ï¼Œæ ‡å‡†å·®ï¼‰\n",
    "* BIAT: å‘åå‘é€ä¸¤ä¸ªæ•°æ®åŒ…ä¹‹é—´çš„æ—¶é—´ï¼ˆå¹³å‡å€¼ï¼Œæœ€å¤§å€¼ï¼Œæœ€å°å€¼ï¼Œæ ‡å‡†å·®ï¼‰\n",
    "* FLOWIAT: å½¢æˆæ•°æ®æµçš„ä¸¤ä¸ªæ•°æ®åŒ…ä¹‹é—´çš„æ—¶é—´ï¼ˆå¹³å‡å€¼ï¼Œæœ€å¤§å€¼ï¼Œæœ€å°å€¼ï¼Œæ ‡å‡†å·®ï¼‰\n",
    "* ACTIVE: æ—¶é—´é‡ï¼Œåœ¨å˜æˆç©ºé—²ä¹‹å‰çš„æ´»è·ƒæ—¶é—´\n",
    "* IDLE: æ—¶é—´é‡ï¼Œåœ¨å˜æˆæ´»è·ƒä¹‹å‰çš„ç©ºé—²æ—¶é—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = pd.read_csv('../data/15s.csv')\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 è§‚å¯Ÿæ•°æ®åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i in range(len(pd_data.keys())-1):\n",
    "    key = pd_data.keys()[i]\n",
    "    plt.subplot(6,4,i+1)\n",
    "    plt.xlabel(key)\n",
    "    plt.hist(pd_data[key],bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 å¤„ç†æ•°æ®\n",
    "* æ•°æ®æ‰“ä¹±\n",
    "* åˆ¶ä½œæ ‡ç­¾\n",
    "* æ•°æ®å½’ä¸€\n",
    "* æ•°æ®é›†åˆ’åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(labels):\n",
    "    return np.where(labels=='VPN',1,0)\n",
    "\n",
    "def create_datas(pd_data):\n",
    "    shuffled_datas = pd_data.sample(frac=1.0)\n",
    "    labels = create_labels(np.array(shuffled_datas.label))\n",
    "    norm_datas = shuffled_datas.drop('label', axis=1)\n",
    "    norm_datas_min = norm_datas.min(0)\n",
    "    norm_datas_max = norm_datas.max(0)\n",
    "    norm_datas = (norm_datas - norm_datas_min) / (norm_datas_max - norm_datas_min)\n",
    "    numpy_datas = np.array(norm_datas)\n",
    "    test_x, test_y = numpy_datas[0:2000], labels[0:2000]\n",
    "    train_x, train_y = numpy_datas[2000:], labels[2000:]\n",
    "    print(\"æµ‹è¯•æ•°æ®ä¸æ ‡ç­¾ï¼š{} | {}\".format(test_x.shape, test_y.shape))\n",
    "    print(\"è®­ç»ƒæ•°æ®ä¸æ ‡ç­¾ï¼š{} | {}\".format(train_x.shape, train_y.shape))\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = create_datas(pd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ä½¿ç”¨ Tensorflow å»ºç«‹æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0007\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_x = log.epoch[::10]\n",
    "plt_y1 = log.history['loss'][::10]\n",
    "plt_y2 = log.history['val_loss'][::10]\n",
    "plt.plot(plt_x, plt_y1, 'b-')\n",
    "plt.plot(plt_x, plt_y2, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt_y3 = log.history['acc'][::10]\n",
    "plt_y4 = log.history['val_acc'][::10]\n",
    "plt.plot(plt_x, plt_y3, 'b-')\n",
    "plt.plot(plt_x, plt_y4, 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 æµ‹è¯•æ•°æ®é›†éªŒè¯ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_x, test_y, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
